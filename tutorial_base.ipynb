{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c0f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "# import torch.nn as nn \n",
    "# import torch.optim as optim \n",
    "from torch.optim import lr_scheduler \n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228316cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "# Verifica se a GPU está disponível\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('\\nDevice: {0}'.format(DEVICE))\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbdb9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f76eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define o caminho base do diretório de imagens\n",
    "base_dir = 'data'\n",
    "ds_path = os.path.join(base_dir, 'RoCole\\sorted_binary')\n",
    "\n",
    "# Número de classes\n",
    "num_classes = 2\n",
    "\n",
    "# Nomes das classes\n",
    "class_names = ['healthy', 'unhealthy']\n",
    "\n",
    "# Tamanho do lote (mini-batch)\n",
    "batch_size = 64\n",
    "\n",
    "# Taxa de aprendizado\n",
    "lr = 0.001\n",
    "\n",
    "# Mommentum\n",
    "mm = 0.9\n",
    "\n",
    "# Número de épocas\n",
    "epochs = 5 # Usar durante o desenvolvimento\n",
    "### epochs = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    ### transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    # Média e desvio padrão do ImageNet.\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(ds_path, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_transformed_image(image):\n",
    "    # Unnormalize all channels \n",
    "    ### for t, m, s in zip(np_image, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]):\n",
    "    for t, m, s in zip(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]): # (ImageNet weights)       \n",
    "        t.mul_(s).add_(m)\n",
    "\n",
    "    np_image = image.numpy()\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(np.transpose(np_image, (1, 2, 0)))\n",
    "\n",
    "# Visualizar 'batch_size' imagens\n",
    "dataloader_vis = torch.utils.data.DataLoader(dataset=full_dataset, shuffle=True, batch_size=64)\n",
    "items = iter(dataloader_vis)\n",
    "image, label = next(items)\n",
    "\n",
    "show_transformed_image(utils.make_grid(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de treinamento: 80 %\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "# Conjunto de validação: 20 %\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "# Spliting the full dataset\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "# Número de imagens em cada dataset\n",
    "train_size = len(train_dataset)\n",
    "val_size = len(val_dataset)\n",
    "\n",
    "# DEBUG\n",
    "print(train_size)\n",
    "print(val_size)\n",
    "\n",
    "# Definindo os dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d668d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Consider each image having 32 rowns by 32 columns.\n",
    "    Input [3, 32, 32] \n",
    "    Conv1(3, 6, 5) [6, 28, 28] \n",
    "    Pool(2, 2) [6, 14, 14] \n",
    "    Conv2(6, 16, 5) [16, 10, 10]\n",
    "    Pool(2, 2) [16, 5, 5]\n",
    "    Flatten [400]\n",
    "    Fc1 [120]\n",
    "    Fc2 [84]\n",
    "    Fc3 [10]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        \"\"\"\n",
    "        torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "        torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Consider each image having 32 rowns by 32 columns.\n",
    "        \"\"\"\n",
    "        # conv1(x): Input: [32, 32, 3]. Output: [28, 28, 6].\n",
    "        #   Como padding=0 e kernel_size=5, a imagem é \"reduzida\" 2 linhas (5-1/2 = 2) acima e abaixo e 2 colunas à esquerda e à direita.\n",
    "        # pool: Input: [28, 28, 6], Output: [14, 14, 6]\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # conv2: Input: [14, 14, 6]. Output: [10, 10, 16].\n",
    "        #   Como padding=0 e kernel_size=5, a imagem é \"reduzida\" 2 linhas (5-1/2 = 2) acima e abaixo e 2 colunas à esquerda e à direita.\n",
    "        # pool: Input: [10, 10, 16], Output: [5, 5, 16]\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flatten: Input: [5, 5, 16]. Output: [400]\n",
    "        x = torch.flatten(x, 1) \n",
    "        # fc1: Input: [400]. Output: [120]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # fc2: Input: [120]. Output: [80]\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # fc3: Input: [80]. Output: [num_classes]\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### model_ft = models.alexnet(pretrained=True)\n",
    "model_ft = models.alexnet(weights='AlexNet_Weights.DEFAULT')\n",
    "\n",
    "# Altera o número de neurônios na cadama de saída.\n",
    "model_ft.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "# Simple net\n",
    "### model = Net(3, 5)\n",
    "\n",
    "# Pretrainned\n",
    "model = model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envia o modelo para a GPU\n",
    "if DEVICE.type == 'cuda':\n",
    "    model = model.cuda() # Cuda\n",
    "    \n",
    "# Imprime o modelo\n",
    "print(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de perda\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Otimizador\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=mm)\n",
    "\n",
    "# Tempo total do treinamento (treinamento e validação)\n",
    "time_total_start = time.time()\n",
    "\n",
    "# Lista das perdas (loss) e acurácias (accuracy) de trino para cada época.\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "# Lista das perdas (loss) e acurácias (accuracy) de validação para cada época.\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # TREINAMENTO\n",
    "    # =========================================================================\n",
    "    # Inicia contagem de tempo da época\n",
    "    time_epoch_start = time.time()\n",
    "\n",
    "    # Habilita o modelo para o modo de treino \n",
    "    model.train() \n",
    "\n",
    "    # Perda (loss) nesta época\n",
    "    loss_epoch_train = 0.0    \n",
    "    # Amostras classificadas corretamente nesta época\n",
    "    num_hits_epoch_train = 0  \n",
    "\n",
    "    # Iterate along the batches of the TRAINING SET\n",
    "    for inputs, labels in train_dataloader:\n",
    "\n",
    "        if DEVICE.type == 'cuda':\n",
    "            inputs = inputs.to(DEVICE) \n",
    "            labels = labels.to(DEVICE) \n",
    "\n",
    "        # Zera os parametros do gradiente\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # FORWARD\n",
    "        # ------>\n",
    "        # Habilita o cálculo do gradiente\n",
    "        torch.set_grad_enabled(True) \n",
    "\n",
    "        # Saída do modelo para o lote\n",
    "        outputs = model(inputs) \n",
    "\n",
    "        # 'outputs' está em porcentagens. Tomar os maximos como resposta.\n",
    "        preds = torch.argmax(outputs, dim=1).float() \n",
    "\n",
    "        # Calcula a perda (loss)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # BACKWARD\n",
    "        # <-------\n",
    "        loss.backward() \n",
    "\n",
    "        # Atualiza os parâmetros da rede\n",
    "        optimizer.step()\n",
    "\n",
    "        # Atualiza a perda da época\n",
    "        loss_epoch_train += float(loss.item()) * inputs.size(0) \n",
    "\n",
    "        # Atualiza o número de amostras classificadas corretamente na época.\n",
    "        num_hits_epoch_train += torch.sum(preds == labels.data) \n",
    "\n",
    "    # Perda desta época\n",
    "    train_loss = loss_epoch_train / train_size\n",
    "    # Acurácia desta época\n",
    "    train_acc = float(num_hits_epoch_train.double() / train_size)\n",
    "\n",
    "    # Store loss and accuracy in lists\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # VALIDAÇÃO\n",
    "    # =========================================================================\n",
    "    model.eval() \n",
    "\n",
    "    # Pego o numero de perda e o numero de acertos\n",
    "    loss_epoch_val = 0.0 # Atual perda\n",
    "    num_hits_epoch_val = 0 # Numero de itens corretos\n",
    "    \n",
    "    # Iterate along the batches of the VALIDATION SET\n",
    "    for inputs, labels in val_dataloader:\n",
    "\n",
    "        if DEVICE.type == 'cuda':\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "        # Zera os parametros do gradiente\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # Desabilita o cálculo do gradiente durante a validação.\n",
    "        torch.set_grad_enabled(False) \n",
    "\n",
    "        # Gero um tensor cujas linhas representam o tamanho do \"batch\" do input\n",
    "        outputs = model(inputs) \n",
    "\n",
    "        # Retorna a maior predicao.\n",
    "        #### _, preds = torch.max(outputs, 1) \n",
    "        preds = torch.argmax(outputs, dim=1).float()\n",
    "\n",
    "        # Calcula a perda (loss)\n",
    "        loss = criterion(outputs, labels) \n",
    "\n",
    "        # Atualiza a perda da época\n",
    "        loss_epoch_val += float(loss.item()) * inputs.size(0)\n",
    "        # # Atualiza os acertos da época\n",
    "        num_hits_epoch_val += torch.sum(preds == labels.data)\n",
    "\n",
    "    # Ajusta o learning rate\n",
    "    ### scheduler.step() \n",
    "        \n",
    "    # Perda e acuracia do conjunto de validacao para esta época\n",
    "    val_loss = loss_epoch_val / val_size\n",
    "    val_acc = float(num_hits_epoch_val.double() / val_size)\n",
    "\n",
    "    # Store loss and accuracy in lists\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    # Tempo total desta época\n",
    "    time_epoch = time.time() - time_epoch_start\n",
    "    \n",
    "    # PRINTING\n",
    "    # --------\n",
    "    print('Epoch {}/{} - TRAIN Loss: {:.4f} TRAIN Acc: {:.4f} - VAL. Loss: {:.4f} VAL. Acc: {:.4f} ({:.4f} seconds)'.format(epoch, epochs - 1, train_loss, train_acc, val_loss, val_acc, time_epoch))\n",
    "\n",
    "# Tempo total do treinamento\n",
    "time_total_train = time.time() - time_total_start\n",
    "\n",
    "# PRINTING\n",
    "print('\\nTreinamento finalizado. ({0}m and {1}s)'.format(int(time_total_train // 60), int(time_total_train % 60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0397bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com os indices das épocas. [0, 1, ... num_epochs - 1]\n",
    "epochs_list = []\n",
    "for i in range(len(train_loss_list)):\n",
    "    epochs_list.append(i)\n",
    "\n",
    "# Titulo - Loss and accuracy chart\n",
    "loss_title = 'Loss - ' + str(epochs) + ' epochs'\n",
    "acc_title = 'Accuracy - ' + str(epochs) + ' epochs'\n",
    "\n",
    "# Plot - Loss \n",
    "plt.figure()\n",
    "plt.title(loss_title)\n",
    "plt.plot(epochs_list, train_loss_list, c='magenta' ,ls='--', label='Train loss', fillstyle='none')\n",
    "plt.plot(epochs_list, val_loss_list, c='green' ,ls='--', label='Val. loss', fillstyle='none')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Plot - Accuracy\n",
    "plt.figure()\n",
    "plt.title(acc_title)\n",
    "plt.plot(epochs_list, train_acc_list, c='magenta' ,ls='-', label='Train acuracy', fillstyle='none')\n",
    "plt.plot(epochs_list, val_acc_list, c='green' ,ls='-', label='Val. accuracy', fillstyle='none')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com as classes reais e classes preditas\n",
    "true_val_list = []\n",
    "pred_val_list = []\n",
    "# Lista com as probabilidades\n",
    "prob_val_list = []\n",
    "\n",
    "# Iterate along the batches of the VALIDATION SET\n",
    "for i, (img_list, labelList) in enumerate(val_dataloader):\n",
    "\n",
    "    if DEVICE.type == 'cuda':\n",
    "        img_list = img_list.to(DEVICE)\n",
    "        labelList = labelList.to(DEVICE)\n",
    "\n",
    "    # Desabilita o cálculo do gradiente durante validação e testes.\n",
    "    torch.set_grad_enabled(False) \n",
    "\n",
    "    # -----> FORWARD\n",
    "    # Saída do modelo\n",
    "    outputs = model(img_list)\n",
    "\n",
    "    # Predição\n",
    "    ### _, preds = torch.max(output, 1)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    # Calcula probabilidades \n",
    "    # https://discuss.pytorch.org/t/obtain-probabilities-from-cross-entropy-loss/157259\n",
    "    outputs_prob = nn.functional.softmax(outputs, dim=1)\n",
    "    prob_val_batch = np.asarray(outputs_prob.cpu())\n",
    "\n",
    "    # Classes reais true) e classes preditas (pred) para este lote.\n",
    "    if DEVICE.type == 'cuda':\n",
    "        true_val_batch = np.asarray(labelList.cpu())\n",
    "        pred_val_batch = np.asarray(preds.cpu())\n",
    "        \n",
    "    # Itera ao longo do lote\n",
    "    for i in range(0, len(pred_val_batch)):\n",
    "        true_val_list.append(true_val_batch[i])\n",
    "        pred_val_list.append(pred_val_batch[i])\n",
    "\n",
    "        prob_val_list.append(prob_val_batch[i])\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat_val = metrics.confusion_matrix(true_val_list, pred_val_list)\n",
    "print('\\nConfusion matrix ( validation)')\n",
    "print(conf_mat_val)\n",
    "\n",
    "# Classification report - Scikit-learn\n",
    "class_rep_val = metrics.classification_report(true_val_list, pred_val_list, \n",
    "                                              target_names=class_names, digits=4,\n",
    "                                              zero_division=0)\n",
    "print('\\nClass. report (validation)')\n",
    "print(class_rep_val)\n",
    "\n",
    "# Accuracy\n",
    "acc_val = metrics.accuracy_score(true_val_list, pred_val_list)\n",
    "print('\\n\\nValidation Acc.: {:.4f}'.format(acc_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
